"""
AllerMind Ana Tahmin Sistemi
Grup tabanlÄ± model aktivasyonu ve kiÅŸisel Ã¶zellik entegrasyonu
"""

import pickle
import json
import numpy as np
import pandas as pd
from typing import Dict, List, Optional, Tuple, Any, Union
from datetime import datetime
import os
import logging
from dataclasses import dataclass
import warnings

# Kendi modÃ¼llerimizi import et
from user_preference_system import AllergyGroupClassifier, UserPreferences
from data_loader import DataLoader

warnings.filterwarnings('ignore')
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


@dataclass
class PredictionResult:
    """Tahmin sonucu veri yapÄ±sÄ±"""
    risk_score: float
    confidence: float
    risk_level: str  # low, moderate, high, severe
    group_id: int
    group_name: str
    
    # DetaylÄ± bilgiler
    contributing_factors: Dict[str, float]
    recommendations: List[str]
    environmental_risks: Dict[str, float]
    personal_modifiers_applied: Dict[str, float]
    
    # Metadata
    prediction_timestamp: datetime
    data_quality_score: float
    model_version: str


class AllerMindPredictor:
    """
    Ana AllerMind tahmin sistemi
    KullanÄ±cÄ± grubuna gÃ¶re uygun modeli aktive eder ve kiÅŸisel Ã¶zellikler ekler
    """
    
    def __init__(self, models_path: str = "/Users/elifdy/Desktop/allermind/aller-mind/DATA/MODEL/pkl_models"):
        self.models_path = models_path
        self.data_loader = DataLoader()
        self.group_classifier = AllergyGroupClassifier()
        
        # Model ve konfigÃ¼rasyon yÃ¼kleme
        self.models = {}
        self.scalers = {}
        self.ensemble_config = {}
        
        self._load_models()
        self._load_ensemble_config()
        
        # Risk seviye eÅŸikleri
        self.risk_thresholds = {
            'low': 0.3,
            'moderate': 0.6,
            'high': 0.8,
            'severe': 0.9
        }
        
        # Ä°mmunolojik faktÃ¶r aÄŸÄ±rlÄ±klarÄ±
        self.immunologic_weights = {
            1: {  # Åiddetli Alerjik Grup
                'pollen_sensitivity': 2.0,
                'environmental_amplifier': 1.8,
                'cross_reactivity_bonus': 1.5,
                'weather_sensitivity': 1.6
            },
            2: {  # Hafif-Orta Alerjik Grup  
                'pollen_sensitivity': 1.3,
                'environmental_amplifier': 1.2,
                'cross_reactivity_bonus': 1.1,
                'weather_sensitivity': 1.2
            },
            3: {  # Genetik YatkÄ±nlÄ±k Grubu
                'pollen_sensitivity': 1.5,
                'environmental_amplifier': 1.4,
                'cross_reactivity_bonus': 1.3,
                'weather_sensitivity': 1.1
            },
            4: {  # TeÅŸhis AlmamÄ±ÅŸ Grup
                'pollen_sensitivity': 1.0,
                'environmental_amplifier': 1.0,
                'cross_reactivity_bonus': 1.0,
                'weather_sensitivity': 1.0
            },
            5: {  # Hassas Ã‡ocuk/YaÅŸlÄ± Grubu
                'pollen_sensitivity': 1.8,
                'environmental_amplifier': 2.0,
                'cross_reactivity_bonus': 1.4,
                'weather_sensitivity': 1.7
            }
        }
    
    def _load_models(self):
        """TÃ¼m grup modellerini yÃ¼kle"""
        try:
            for group_id in range(1, 6):
                model_file = f"Grup{group_id}_model.pkl"
                scaler_file = f"Grup{group_id}_scaler.pkl"
                
                model_path = os.path.join(self.models_path, model_file)
                scaler_path = os.path.join(self.models_path, scaler_file)
                
                if os.path.exists(model_path) and os.path.exists(scaler_path):
                    with open(model_path, 'rb') as f:
                        self.models[group_id] = pickle.load(f)
                    
                    with open(scaler_path, 'rb') as f:
                        self.scalers[group_id] = pickle.load(f)
                    
                    logger.info(f"Grup {group_id} modeli yÃ¼klendi")
                else:
                    logger.warning(f"Grup {group_id} model dosyalarÄ± bulunamadÄ±")
        
        except Exception as e:
            logger.error(f"Model yÃ¼kleme hatasÄ±: {e}")
            self._create_fallback_models()
    
    def _load_ensemble_config(self):
        """Ensemble konfigÃ¼rasyonunu yÃ¼kle"""
        try:
            config_path = os.path.join(self.models_path, "ensemble_config.json")
            if os.path.exists(config_path):
                with open(config_path, 'r') as f:
                    self.ensemble_config = json.load(f)
                logger.info("Ensemble konfigÃ¼rasyonu yÃ¼klendi")
            else:
                self._create_default_ensemble_config()
        except Exception as e:
            logger.error(f"Ensemble konfigÃ¼rasyonu yÃ¼kleme hatasÄ±: {e}")
            self._create_default_ensemble_config()
    
    def _create_fallback_models(self):
        """Modeller yÃ¼klenemediÄŸinde basit fallback modeller oluÅŸtur"""
        logger.warning("Fallback modeller oluÅŸturuluyor")
        
        from sklearn.ensemble import RandomForestRegressor
        from sklearn.preprocessing import StandardScaler
        
        # Her grup iÃ§in basit model oluÅŸtur
        for group_id in range(1, 6):
            # Basit Random Forest modeli
            model = RandomForestRegressor(n_estimators=10, random_state=42)
            scaler = StandardScaler()
            
            # Dummy veri ile fit et
            dummy_X = np.random.random((100, 25))  # 25 Ã¶zellik
            dummy_y = np.random.random(100)
            
            scaler.fit(dummy_X)
            model.fit(scaler.transform(dummy_X), dummy_y)
            
            self.models[group_id] = model
            self.scalers[group_id] = scaler
    
    def _create_default_ensemble_config(self):
        """VarsayÄ±lan ensemble konfigÃ¼rasyonu"""
        self.ensemble_config = {
            "models": {
                "1": {"weight": 0.18, "algorithm": "Random Forest"},
                "2": {"weight": 0.22, "algorithm": "RBF SVM"}, 
                "3": {"weight": 0.24, "algorithm": "RBF SVM"},
                "4": {"weight": 0.24, "algorithm": "RBF SVM"},
                "5": {"weight": 0.12, "algorithm": "RBF SVM"}
            },
            "confidence_threshold": 0.95,
            "version": "2.0"
        }
    
    def predict_allergy_risk(self, user_preferences: UserPreferences, 
                           location: Tuple[float, float],
                           target_datetime: Optional[datetime] = None) -> PredictionResult:
    
        
        if target_datetime is None:
            target_datetime = datetime.now()
        
        # 1. Grup belirleme
        group_result = self.group_classifier.determine_allergy_group(user_preferences)
        group_id = group_result['group_id']
        
        logger.info(f"KullanÄ±cÄ± Grup {group_id} olarak sÄ±nÄ±flandÄ±rÄ±ldÄ±: {group_result['group_name']}")
        
        # 2. Model kontrolÃ¼
        if group_id not in self.models:
            logger.error(f"Grup {group_id} modeli bulunamadÄ±")
            return self._create_error_result()
        
        # 3. Ã‡evresel veri hazÄ±rlama
        lat, lon = location
        user_modifiers = group_result['personal_risk_modifiers']
        
        try:
            # Veri yÃ¼kleme
            model_input = self.data_loader.prepare_model_input(
                lat, lon, target_datetime, user_modifiers
            )
            
            # Ã‡evresel veri detaylarÄ±
            environmental_data = self.data_loader.combine_environmental_data(lat, lon, target_datetime)
            
            # 4. Model tahmini
            prediction = self._execute_model_prediction(group_id, model_input)
            
            # 5. Ä°mmunolojik modifikasyonlar uygula
            modified_prediction = self._apply_immunologic_modifiers(
                prediction, group_result, environmental_data
            )
            
            # 6. Risk seviyesi belirleme
            risk_level = self._determine_risk_level(modified_prediction)
            
            # 7. GÃ¼ven aralÄ±ÄŸÄ± hesaplama
            confidence = self._calculate_confidence(group_id, environmental_data)
            
            # 8. KatkÄ± faktÃ¶rlerini analiz et
            contributing_factors = self._analyze_contributing_factors(
                environmental_data, group_result
            )
            
            # 9. Ã–nerileri oluÅŸtur
            recommendations = self._generate_recommendations(
                risk_level, group_result, environmental_data
            )
            
            # 10. Sonucu oluÅŸtur
            result = PredictionResult(
                risk_score=modified_prediction,
                confidence=confidence,
                risk_level=risk_level,
                group_id=group_id,
                group_name=group_result['group_name'],
                contributing_factors=contributing_factors,
                recommendations=recommendations,
                environmental_risks=self._extract_environmental_risks(environmental_data),
                personal_modifiers_applied=user_modifiers,
                prediction_timestamp=target_datetime,
                data_quality_score=environmental_data['metadata']['data_quality_score'],
                model_version=self.ensemble_config.get('version', '1.0')
            )
            
            return result
            
        except Exception as e:
            logger.error(f"Tahmin hatasÄ±: {e}")
            return self._create_error_result()
    
    def _execute_model_prediction(self, group_id: int, model_input: np.ndarray) -> float:
        """Model tahminini Ã§alÄ±ÅŸtÄ±r"""
        try:
            # Veriyi Ã¶lÃ§ekle
            scaled_input = self.scalers[group_id].transform(model_input)
            
            # Tahmin yap
            prediction = self.models[group_id].predict(scaled_input)[0]
            
            # 0-1 aralÄ±ÄŸÄ±nda normalize et
            normalized_prediction = max(0.0, min(1.0, prediction))
            
            return normalized_prediction
            
        except Exception as e:
            logger.error(f"Model Ã§alÄ±ÅŸtÄ±rma hatasÄ±: {e}")
            return 0.5  # VarsayÄ±lan orta risk
    
    def _apply_immunologic_modifiers(self, base_prediction: float, 
                                   group_result: Dict, 
                                   environmental_data: Dict) -> float:
        """Ä°mmunolojik modifikasyonlarÄ± uygula"""
        
        group_id = group_result['group_id']
        weights = self.immunologic_weights.get(group_id, self.immunologic_weights[4])
        
        modified_prediction = base_prediction
        
        # Polen hassasiyet modifikasyonu
        pollen_risk = self._calculate_pollen_risk_factor(environmental_data)
        if pollen_risk > 0.5:  # YÃ¼ksek polen riski
            pollen_modifier = 1.0 + (pollen_risk * weights['pollen_sensitivity'] - 1.0) * 0.3
            modified_prediction *= pollen_modifier
        
        # Ã‡evresel amplifikatÃ¶r
        env_risk = self._calculate_environmental_risk_factor(environmental_data)
        if env_risk > 0.6:  # YÃ¼ksek Ã§evresel risk
            env_modifier = 1.0 + (env_risk * weights['environmental_amplifier'] - 1.0) * 0.2
            modified_prediction *= env_modifier
        
        # Ã‡apraz reaksiyon bonusu
        cross_reactive_plants = group_result.get('pollen_specific_risks', {}).get('cross_reactive_foods', [])
        if cross_reactive_plants:
            cross_modifier = 1.0 + len(cross_reactive_plants) * 0.1 * weights['cross_reactivity_bonus']
            modified_prediction *= cross_modifier
        
        # Hava durumu hassasiyeti
        weather_severity = self._calculate_weather_severity(environmental_data)
        if weather_severity > 0.7:
            weather_modifier = 1.0 + (weather_severity * weights['weather_sensitivity'] - 1.0) * 0.15
            modified_prediction *= weather_modifier
        
        # Sonucu 0-1 aralÄ±ÄŸÄ±nda tut
        return max(0.0, min(1.0, modified_prediction))
    
    def _calculate_pollen_risk_factor(self, environmental_data: Dict) -> float:
        """Polen risk faktÃ¶rÃ¼nÃ¼ hesapla"""
        total_upi = environmental_data.get('total_upi', 0.0)
        in_season_count = environmental_data.get('in_season_count', 0)
        diversity_index = environmental_data.get('pollen_diversity_index', 0.0)
        
        # UPI tabanlÄ± risk (0-5 arasÄ± UPI'Ä± 0-1'e normalize et)
        upi_risk = min(1.0, total_upi / 5.0)
        
        # Mevsim iÃ§i polen sayÄ±sÄ± riski
        season_risk = min(1.0, in_season_count / 10.0)
        
        # Ã‡eÅŸitlilik riski
        diversity_risk = diversity_index
        
        # AÄŸÄ±rlÄ±klÄ± ortalama
        return (upi_risk * 0.5 + season_risk * 0.3 + diversity_risk * 0.2)
    
    def _calculate_environmental_risk_factor(self, environmental_data: Dict) -> float:
        """Ã‡evresel risk faktÃ¶rÃ¼nÃ¼ hesapla"""
        # Hava kalitesi parametreleri
        pm25 = environmental_data.get('pm2_5', 0.0)
        ozone = environmental_data.get('ozone', 0.0)
        no2 = environmental_data.get('nitrogen_dioxide', 0.0)
        
        # Risk skorlarÄ± (WHO sÄ±nÄ±rlarÄ±na gÃ¶re)
        pm25_risk = min(1.0, pm25 / 25.0)  # WHO gÃ¼nlÃ¼k sÄ±nÄ±r: 15 Âµg/mÂ³
        ozone_risk = min(1.0, ozone / 100.0)  # WHO 8-saatlik ortalama: 100 Âµg/mÂ³
        no2_risk = min(1.0, no2 / 40.0)  # WHO yÄ±llÄ±k ortalama: 40 Âµg/mÂ³
        
        # AÄŸÄ±rlÄ±klÄ± ortalama
        return (pm25_risk * 0.4 + ozone_risk * 0.3 + no2_risk * 0.3)
    
    def _calculate_weather_severity(self, environmental_data: Dict) -> float:
        """Hava durumu ÅŸiddeti faktÃ¶rÃ¼nÃ¼ hesapla"""
        # Alerjiyi tetikleyebilecek hava durumu koÅŸullarÄ±
        humidity = environmental_data.get('relative_humidity_2m', 50.0)
        temperature = environmental_data.get('temperature_2m', 20.0)
        wind_speed = environmental_data.get('wind_speed_10m', 0.0)
        
        # Nem riski (Ã§ok yÃ¼ksek veya Ã§ok dÃ¼ÅŸÃ¼k nem)
        humidity_risk = 0.0
        if humidity > 80 or humidity < 30:
            humidity_risk = min(1.0, abs(humidity - 55) / 45)
        
        # SÄ±caklÄ±k riski (aÅŸÄ±rÄ± sÄ±caklÄ±k)
        temp_risk = 0.0
        if temperature > 30:
            temp_risk = min(1.0, (temperature - 30) / 20)
        
        # RÃ¼zgar riski (polen taÅŸÄ±yÄ±cÄ±)
        wind_risk = min(1.0, wind_speed / 20.0)
        
        return (humidity_risk * 0.4 + temp_risk * 0.3 + wind_risk * 0.3)
    
    def _determine_risk_level(self, risk_score: float) -> str:
        """Risk skoruna gÃ¶re risk seviyesi belirle"""
        if risk_score >= self.risk_thresholds['severe']:
            return 'severe'
        elif risk_score >= self.risk_thresholds['high']:
            return 'high'
        elif risk_score >= self.risk_thresholds['moderate']:
            return 'moderate'
        else:
            return 'low'
    
    def _calculate_confidence(self, group_id: int, environmental_data: Dict) -> float:
        """Tahmin gÃ¼ven aralÄ±ÄŸÄ±nÄ± hesapla"""
        # Temel gÃ¼ven skoru (model performansÄ±na gÃ¶re)
        model_performance = self.ensemble_config.get('models', {}).get(str(group_id), {})
        base_confidence = model_performance.get('performance', {}).get('r2', 0.8)
        
        # Veri kalitesi faktÃ¶rÃ¼
        data_quality = environmental_data.get('metadata', {}).get('data_quality_score', 0.7)
        
        # BirleÅŸtirilmiÅŸ gÃ¼ven skoru
        combined_confidence = (base_confidence * 0.7 + data_quality * 0.3)
        
        return max(0.5, min(1.0, combined_confidence))
    
    def _analyze_contributing_factors(self, environmental_data: Dict, 
                                    group_result: Dict) -> Dict[str, float]:
        """KatkÄ± faktÃ¶rlerini analiz et"""
        factors = {}
        
        # Polen faktÃ¶rleri
        factors['pollen_contribution'] = self._calculate_pollen_risk_factor(environmental_data)
        
        # Hava kalitesi faktÃ¶rleri
        factors['air_quality_contribution'] = self._calculate_environmental_risk_factor(environmental_data)
        
        # Hava durumu faktÃ¶rleri
        factors['weather_contribution'] = self._calculate_weather_severity(environmental_data)
        
        # KiÅŸisel risk faktÃ¶rleri
        personal_modifiers = group_result.get('personal_risk_modifiers', {})
        factors['personal_sensitivity'] = personal_modifiers.get('base_sensitivity', 1.0) - 1.0
        factors['environmental_amplification'] = personal_modifiers.get('environmental_amplifier', 1.0) - 1.0
        
        return factors
    
    def _generate_recommendations(self, risk_level: str, group_result: Dict, 
                                environmental_data: Dict) -> List[str]:
        """Risk seviyesi ve grup bilgisine gÃ¶re Ã¶neriler Ã¼ret"""
        recommendations = []
        
        # Risk seviyesi bazlÄ± Ã¶neriler
        if risk_level == 'severe':
            recommendations.extend([
                "ğŸš¨ ACÄ°L: DÄ±ÅŸarÄ± Ã§Ä±kmayÄ±n, ilaÃ§larÄ±nÄ±zÄ± kontrol edin",
                "ğŸ’Š Acil ilaÃ§ (epinefrin) yanÄ±nÄ±zda olsun",
                "ğŸ¥ Gerekirse saÄŸlÄ±k kuruluÅŸuna baÅŸvurun"
            ])
        elif risk_level == 'high':
            recommendations.extend([
                "âš ï¸ DÄ±ÅŸarÄ± Ã§Ä±kmadan Ã¶nce maske takÄ±n",
                "ğŸ’Š Antihistaminik alÄ±n",
                "ğŸªŸ Pencere ve kapÄ±larÄ± kapalÄ± tutun"
            ])
        elif risk_level == 'moderate':
            recommendations.extend([
                "ğŸ˜· DÄ±ÅŸ ortamda maske kullanmayÄ± dÃ¼ÅŸÃ¼nÃ¼n",
                "â° Sabah erken veya akÅŸam saatlerini tercih edin",
                "ğŸš¿ Eve dÃ¶ndÃ¼ÄŸÃ¼nÃ¼zde duÅŸ alÄ±n"
            ])
        else:  # low
            recommendations.extend([
                "ğŸ˜Š DÄ±ÅŸ ortam aktiviteleri iÃ§in uygun",
                "ğŸŒ³ Park ve bahÃ§e aktivitelerini gÃ¼venle yapabilirsiniz"
            ])
        
        # Polen Ã¶zel Ã¶neriler
        high_risk_pollens = group_result.get('pollen_specific_risks', {}).get('high_risk_pollens', [])
        if high_risk_pollens:
            recommendations.append(f"ğŸŒ¿ Dikkat: {', '.join(high_risk_pollens)} polenlerine karÅŸÄ± ekstra tedbirli olun")
        
        # Ã‡apraz reaktif besinler
        cross_foods = group_result.get('pollen_specific_risks', {}).get('cross_reactive_foods', [])
        if cross_foods:
            recommendations.append(f"ğŸ Ã‡apraz reaksiyon riski: {', '.join(cross_foods)} tÃ¼ketiminde dikkatli olun")
        
        # Grup Ã¶zel Ã¶neriler
        group_id = group_result['group_id']
        if group_id == 1:  # Åiddetli alerjik
            recommendations.append("âš•ï¸ DÃ¼zenli hekim kontrolÃ¼ ve immÃ¼noterapi deÄŸerlendirmesi")
        elif group_id == 5:  # Hassas grup
            recommendations.append("ğŸ‘¶ğŸ‘´ YaÅŸ grubunuz nedeniyle ekstra dikkatli olun")
        
        return recommendations
    
    def _extract_environmental_risks(self, environmental_data: Dict) -> Dict[str, float]:
        """Ã‡evresel risk faktÃ¶rlerini Ã§Ä±kar"""
        return {
            'pm2_5_level': environmental_data.get('pm2_5', 0.0),
            'ozone_level': environmental_data.get('ozone', 0.0),
            'pollen_upi': environmental_data.get('total_upi', 0.0),
            'humidity_level': environmental_data.get('relative_humidity_2m', 0.0),
            'temperature': environmental_data.get('temperature_2m', 0.0)
        }
    
    def _create_error_result(self) -> PredictionResult:
        """Hata durumunda varsayÄ±lan sonuÃ§ oluÅŸtur"""
        return PredictionResult(
            risk_score=0.5,
            confidence=0.3,
            risk_level='moderate',
            group_id=4,
            group_name='TeÅŸhis AlmamÄ±ÅŸ Grup',
            contributing_factors={'error': 1.0},
            recommendations=["âŒ Sistem hatasÄ± oluÅŸtu, lÃ¼tfen tekrar deneyin"],
            environmental_risks={},
            personal_modifiers_applied={},
            prediction_timestamp=datetime.now(),
            data_quality_score=0.0,
            model_version='error'
        )
    
    def batch_predict(self, users_data: List[Dict], 
                     locations: List[Tuple[float, float]],
                     target_datetime: Optional[datetime] = None) -> List[PredictionResult]:
        """Ã‡oklu kullanÄ±cÄ± iÃ§in toplu tahmin"""
        results = []
        
        for user_data, location in zip(users_data, locations):
            try:
                # UserPreferences nesnesini oluÅŸtur
                user_prefs = UserPreferences(**user_data)
                
                # Tahmin yap
                result = self.predict_allergy_risk(user_prefs, location, target_datetime)
                results.append(result)
                
            except Exception as e:
                logger.error(f"Toplu tahmin hatasÄ±: {e}")
                results.append(self._create_error_result())
        
        return results
    
    def get_model_info(self) -> Dict[str, Any]:
        """Model bilgilerini dÃ¶ndÃ¼r"""
        return {
            'loaded_models': list(self.models.keys()),
            'ensemble_config': self.ensemble_config,
            'data_loader_features': self.data_loader.get_feature_names(),
            'risk_thresholds': self.risk_thresholds,
            'immunologic_weights': self.immunologic_weights
        }


# Test fonksiyonlarÄ±
def create_test_user() -> UserPreferences:
    """Test kullanÄ±cÄ±sÄ± oluÅŸtur"""
    return UserPreferences(
        age=35,
        gender='female',
        location={'latitude': 41.0082, 'longitude': 28.9784},
        clinical_diagnosis='mild_moderate_allergy',
        family_allergy_history=True,
        previous_allergic_reactions={
            'anaphylaxis': False,
            'severe_asthma': True,
            'hospitalization': False
        },
        current_medications=['antihistamine', 'nasal_spray'],
        tree_pollen_allergy={
            'birch': True,
            'olive': False,
            'pine': False
        },
        grass_pollen_allergy={
            'graminales': True
        },
        weed_pollen_allergy={
            'ragweed': True,
            'mugwort': False
        },
        food_allergies={
            'apple': True,
            'nuts': False,
            'shellfish': False
        },
        environmental_triggers={
            'dust_mites': True,
            'pet_dander': False,
            'mold': True,
            'air_pollution': True,
            'smoke': True
        }
    )


def test_predictor():
    """Tahmin sistemini test et"""
    print("=== ALLERMÄ°ND TAHMÄ°N SÄ°STEMÄ° TEST ===")
    
    # Predictor oluÅŸtur
    predictor = AllerMindPredictor()
    
    # Test kullanÄ±cÄ±sÄ±
    test_user = create_test_user()
    
    # Test konumu (Ä°stanbul)
    test_location = (41.0082, 28.9784)
    
    # Tahmin yap
    result = predictor.predict_allergy_risk(test_user, test_location)
    
    # SonuÃ§larÄ± yazdÄ±r
    print(f"\nğŸ“Š TAHMÄ°N SONUÃ‡LARI:")
    print(f"Risk Skoru: {result.risk_score:.3f}")
    print(f"Risk Seviyesi: {result.risk_level.upper()}")
    print(f"GÃ¼ven AralÄ±ÄŸÄ±: {result.confidence:.2f}")
    print(f"Grup: {result.group_name} (ID: {result.group_id})")
    
    print(f"\nğŸ§¬ KATKIDA BULUNAN FAKTÃ–RLER:")
    for factor, value in result.contributing_factors.items():
        print(f"  {factor}: {value:.3f}")
    
    print(f"\nğŸ’¡ Ã–NERÄ°LER:")
    for i, rec in enumerate(result.recommendations, 1):
        print(f"  {i}. {rec}")
    
    print(f"\nğŸŒ¡ï¸ Ã‡EVRESEL RÄ°SKLER:")
    for risk, value in result.environmental_risks.items():
        print(f"  {risk}: {value:.2f}")
    
    return predictor


if __name__ == "__main__":
    test_predictor()