import pandas as pd
import numpy as np
from typing import Dict, List, Tuple, Any
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score
import pickle
import json

class AllergyGroupPredictor:
    """
    5 farklÄ± allerji grubu iÃ§in Ã¶zelleÅŸtirilmiÅŸ tahmin modeli
    """
    
    def __init__(self):
        self.groups = {
            1: "Åiddetli Alerjik Grup",
            2: "Hafif-Orta Grup", 
            3: "OlasÄ± Alerjik Grup/GenetiÄŸinde Olan",
            4: "HenÃ¼z TeÅŸhis AlmamÄ±ÅŸ/Ä°htimali Bilinmeyen Grup",
            5: "Alerjisi Olmayan + Ä°htimali Bilinmeyen Ama Hassas Grup"
        }
        
        # Her grup iÃ§in Ã¶zellik aÄŸÄ±rlÄ±klarÄ±
        self.group_weights = self._define_group_weights()
        
        # Model ve scaler'lar her grup iÃ§in
        self.models = {}
        self.scalers = {}
        self.label_encoders = {}
        
    def _define_group_weights(self) -> Dict[int, Dict[str, float]]:
        """
        Her allerji grubu iÃ§in parametrelerin Ã¶nem aÄŸÄ±rlÄ±klarÄ±nÄ± tanÄ±mla
        """
        weights = {
            # Grup 1: Åiddetli Alerjik Grup - Polen ve hava kalitesine Ã§ok hassas
            1: {
                'pollen_importance': 0.40,      # En yÃ¼ksek polen hassasiyeti
                'air_quality_importance': 0.35, # YÃ¼ksek hava kalitesi hassasiyeti
                'weather_importance': 0.25,     # Hava durumu da Ã¶nemli
                'seasonal_factor': 2.0,         # Mevsimsel etkiler Ã§ok Ã¶nemli
                'plant_proximity_factor': 2.5,  # Bitki yakÄ±nlÄ±ÄŸÄ± kritik
                'sensitivity_threshold': 0.2    # Ã‡ok dÃ¼ÅŸÃ¼k tolerans
            },
            
            # Grup 2: Hafif-Orta Grup - Dengeli hassasiyet
            2: {
                'pollen_importance': 0.30,
                'air_quality_importance': 0.30,
                'weather_importance': 0.40,
                'seasonal_factor': 1.5,
                'plant_proximity_factor': 1.8,
                'sensitivity_threshold': 0.4
            },
            
            # Grup 3: OlasÄ± Alerjik Grup - Genetik yatkÄ±nlÄ±k, orta hassasiyet
            3: {
                'pollen_importance': 0.35,
                'air_quality_importance': 0.25,
                'weather_importance': 0.40,
                'seasonal_factor': 1.7,
                'plant_proximity_factor': 2.0,
                'sensitivity_threshold': 0.3
            },
            
            # Grup 4: TeÅŸhis AlmamÄ±ÅŸ - Belirsizlik, temkinli yaklaÅŸÄ±m
            4: {
                'pollen_importance': 0.25,
                'air_quality_importance': 0.35,
                'weather_importance': 0.40,
                'seasonal_factor': 1.3,
                'plant_proximity_factor': 1.5,
                'sensitivity_threshold': 0.5
            },
            
            # Grup 5: Hassas Grup (Ã‡ocuk/YaÅŸlÄ±) - Genel hava kalitesi odaklÄ±
            5: {
                'pollen_importance': 0.20,
                'air_quality_importance': 0.45,  # En yÃ¼ksek hava kalitesi odaÄŸÄ±
                'weather_importance': 0.35,
                'seasonal_factor': 1.2,
                'plant_proximity_factor': 1.0,
                'sensitivity_threshold': 0.6
            }
        }
        
        print("âœ… Grup aÄŸÄ±rlÄ±klarÄ± tanÄ±mlandÄ±:")
        for group_id, group_name in self.groups.items():
            print(f"   Grup {group_id}: {group_name}")
            w = weights[group_id]
            print(f"      ğŸ“Š Polen: {w['pollen_importance']:.1%}, "
                  f"Hava Kalitesi: {w['air_quality_importance']:.1%}, "
                  f"Hava Durumu: {w['weather_importance']:.1%}")
        
        return weights
    
    def create_composite_risk_score(self, df: pd.DataFrame, group_id: int) -> np.ndarray:
        """
        Belirtilen grup iÃ§in bileÅŸik risk skoru oluÅŸtur
        """
        weights = self.group_weights[group_id]
        
        # Polen riski hesapla
        pollen_risk = self._calculate_pollen_risk(df, weights)
        
        # Hava kalitesi riski hesapla
        air_quality_risk = self._calculate_air_quality_risk(df, weights)
        
        # Hava durumu riski hesapla
        weather_risk = self._calculate_weather_risk(df, weights)
        
        # BileÅŸik risk skoru
        composite_risk = (
            pollen_risk * weights['pollen_importance'] +
            air_quality_risk * weights['air_quality_importance'] +
            weather_risk * weights['weather_importance']
        )
        
        return composite_risk
    
    def _calculate_pollen_risk(self, df: pd.DataFrame, weights: Dict[str, float]) -> np.ndarray:
        """Polen riski hesapla"""
        # UPI deÄŸeri normalize et (1-5 arasÄ±)
        upi_normalized = (df['upi_value'] - 1) / 4
        plant_upi_normalized = (df['plant_upi_value'] - 1) / 4
        
        # Mevsimsel etki
        seasonal_multiplier = np.where(
            (df['in_season'] == True) & (df['plant_in_season'] == True),
            weights['seasonal_factor'],
            1.0
        )
        
        # Polen tÃ¼rÃ¼ aÄŸÄ±rlÄ±ÄŸÄ±
        pollen_type_weight = df['pollen_code'].map({
            'WEED': 1.2,    # Yabani ot poleni en zararlÄ±
            'GRASS': 1.0,   # Ã‡im poleni orta
            'TREE': 0.8     # AÄŸaÃ§ poleni nispeten daha az
        }).fillna(1.0)
        
        # Bitki tÃ¼rÃ¼ aÄŸÄ±rlÄ±ÄŸÄ±
        plant_type_weight = df['plant_code'].map({
            'RAGWEED': 1.3,   # En alerjik bitki
            'MUGWORT': 1.2,   # YÃ¼ksek alerjik
            'GRAMINALES': 1.0, # Orta alerjik
            'BIRCH': 0.9,     # DÃ¼ÅŸÃ¼k alerjik
            'OLIVE': 0.7      # En dÃ¼ÅŸÃ¼k alerjik
        }).fillna(1.0)
        
        # Final polen riski
        pollen_risk = (
            (upi_normalized * 0.6 + plant_upi_normalized * 0.4) *
            seasonal_multiplier *
            pollen_type_weight *
            plant_type_weight *
            weights['plant_proximity_factor']
        )
        
        return np.clip(pollen_risk, 0, 1)
    
    def _calculate_air_quality_risk(self, df: pd.DataFrame, weights: Dict[str, float]) -> np.ndarray:
        """Hava kalitesi riski hesapla"""
        # WHO standartlarÄ±na gÃ¶re normalize et
        pm10_risk = np.clip(df['pm10'] / 50, 0, 2)  # WHO gÃ¼nlÃ¼k limit 50
        pm25_risk = np.clip(df['pm2_5'] / 25, 0, 2)  # WHO gÃ¼nlÃ¼k limit 25
        
        no2_risk = np.clip(df['nitrogen_dioxide'] / 40, 0, 2)  # WHO yÄ±llÄ±k limit 40
        so2_risk = np.clip(df['sulphur_dioxide'] / 20, 0, 2)   # WHO gÃ¼nlÃ¼k limit 20
        ozone_risk = np.clip(df['ozone'] / 100, 0, 2)          # WHO 8-saatlik limit 100
        
        co_risk = np.clip(df['carbon_monoxide'] / 10000, 0, 2) # WHO 8-saatlik limit 10mg/m3
        
        # AÄŸÄ±rlÄ±klÄ± ortalama
        air_quality_risk = (
            pm25_risk * 0.25 +    # PM2.5 en zararlÄ±
            pm10_risk * 0.20 +    # PM10 ikinci sÄ±rada
            ozone_risk * 0.20 +   # Ozon Ã¶nemli
            no2_risk * 0.15 +     # NO2 orta
            so2_risk * 0.10 +     # SO2 dÃ¼ÅŸÃ¼k
            co_risk * 0.10        # CO en dÃ¼ÅŸÃ¼k
        )
        
        return np.clip(air_quality_risk, 0, 1)
    
    def _calculate_weather_risk(self, df: pd.DataFrame, weights: Dict[str, float]) -> np.ndarray:
        """Hava durumu riski hesapla"""
        # SÄ±caklÄ±k riski (25-30Â°C optimal, dÄ±ÅŸÄ±nda artan risk)
        temp_risk = np.where(
            (df['temperature_2m'] < 15) | (df['temperature_2m'] > 35),
            0.8,
            np.where(
                (df['temperature_2m'] < 20) | (df['temperature_2m'] > 30),
                0.4,
                0.1
            )
        )
        
        # Nem riski (40-60% optimal)
        humidity_risk = np.where(
            (df['relative_humidity_2m'] < 30) | (df['relative_humidity_2m'] > 80),
            0.6,
            np.where(
                (df['relative_humidity_2m'] < 40) | (df['relative_humidity_2m'] > 70),
                0.3,
                0.0
            )
        )
        
        # RÃ¼zgar hÄ±zÄ± (yÃ¼ksek rÃ¼zgar polen daÄŸÄ±lÄ±mÄ±nÄ± artÄ±rÄ±r)
        wind_risk = np.clip(df['wind_speed_10m'] / 20, 0, 1)  # 20 m/s Ã¼zeri maksimum risk
        
        # UV indeksi riski
        uv_risk = np.where(
            df['uv_index'] > 8, 0.8,
            np.where(df['uv_index'] > 5, 0.4, 0.1)
        )
        
        # YaÄŸÄ±ÅŸ (dÃ¼ÅŸÃ¼k yaÄŸÄ±ÅŸ polen konsantrasyonunu artÄ±rÄ±r)
        rain_benefit = np.where(df['precipitation'] > 0.1, -0.3, 0)  # YaÄŸÄ±ÅŸ riski azaltÄ±r
        
        weather_risk = (
            temp_risk * 0.3 +
            humidity_risk * 0.25 +
            wind_risk * 0.2 +
            uv_risk * 0.15 +
            rain_benefit * 0.1
        )
        
        return np.clip(weather_risk, 0, 1)
    
    def calculate_safe_time_hours(self, risk_score: float, group_id: int) -> float:
        """
        Risk skoruna ve gruba gÃ¶re gÃ¼venli vakit geÃ§irme sÃ¼resi hesapla (saat cinsinden)
        """
        threshold = self.group_weights[group_id]['sensitivity_threshold']
        
        if risk_score <= threshold:
            # DÃ¼ÅŸÃ¼k risk: 6-8 saat gÃ¼venli
            safe_hours = 8 - (risk_score / threshold) * 2
        elif risk_score <= threshold * 1.5:
            # Orta risk: 2-4 saat gÃ¼venli
            safe_hours = 4 - ((risk_score - threshold) / (threshold * 0.5)) * 2
        elif risk_score <= threshold * 2:
            # YÃ¼ksek risk: 0.5-1 saat gÃ¼venli
            safe_hours = 1 - ((risk_score - threshold * 1.5) / (threshold * 0.5)) * 0.5
        else:
            # Ã‡ok yÃ¼ksek risk: DÄ±ÅŸarÄ± Ã§Ä±kma Ã¶nerilmez
            safe_hours = 0.0
        
        return max(0.0, safe_hours)
    
    def prepare_features(self, df: pd.DataFrame) -> Tuple[pd.DataFrame, List[str]]:
        """
        Model iÃ§in Ã¶zellikleri hazÄ±rla
        """
        feature_df = df.copy()
        
        # Kategorik deÄŸiÅŸkenleri encode et
        categorical_columns = ['pollen_code', 'plant_code', 'in_season', 'plant_in_season']
        
        for col in categorical_columns:
            if col in feature_df.columns:
                if col not in self.label_encoders:
                    self.label_encoders[col] = LabelEncoder()
                    feature_df[f'{col}_encoded'] = self.label_encoders[col].fit_transform(
                        feature_df[col].astype(str)
                    )
                else:
                    feature_df[f'{col}_encoded'] = self.label_encoders[col].transform(
                        feature_df[col].astype(str)
                    )
        
        # Zaman Ã¶zellikleri oluÅŸtur
        if 'time' in feature_df.columns:
            feature_df['time'] = pd.to_datetime(feature_df['time'])
            feature_df['hour'] = feature_df['time'].dt.hour
            feature_df['day_of_year'] = feature_df['time'].dt.dayofyear
        
        # Ã–zellik kolonlarÄ±nÄ± seÃ§
        feature_columns = [
            # Hava durumu
            'temperature_2m', 'relative_humidity_2m', 'precipitation',
            'wind_speed_10m', 'wind_direction_10m', 'uv_index',
            
            # Hava kalitesi
            'pm10', 'pm2_5', 'nitrogen_dioxide', 'sulphur_dioxide', 'ozone',
            'carbon_monoxide', 'methane',
            
            # Polen
            'upi_value', 'plant_upi_value',
            'pollen_code_encoded', 'plant_code_encoded',
            'in_season_encoded', 'plant_in_season_encoded',
            
            # Zaman
            'hour', 'day_of_year'
        ]
        
        # Sadece mevcut kolonlarÄ± al
        available_features = [col for col in feature_columns if col in feature_df.columns]
        
        return feature_df[available_features], available_features
    
    def train_group_models(self, df: pd.DataFrame):
        """
        Her grup iÃ§in ayrÄ± model eÄŸit
        """
        print("ğŸ¤– Grup modellerini eÄŸitiyor...")
        
        # Ã–zellikleri hazÄ±rla
        feature_df, feature_columns = self.prepare_features(df)
        
        for group_id in range(1, 6):
            print(f"\nğŸ“š Grup {group_id} modeli eÄŸitiliyor: {self.groups[group_id]}")
            
            # Bu grup iÃ§in risk skoru hesapla
            risk_scores = self.create_composite_risk_score(df, group_id)
            
            # GÃ¼venli vakit sÃ¼relerini hesapla
            safe_times = np.array([
                self.calculate_safe_time_hours(risk, group_id) for risk in risk_scores
            ])
            
            # Veriyi bÃ¶l
            X_train, X_test, y_train, y_test = train_test_split(
                feature_df, safe_times, test_size=0.2, random_state=42
            )
            
            # Ã–zellik Ã¶lÃ§ekleme
            self.scalers[group_id] = StandardScaler()
            X_train_scaled = self.scalers[group_id].fit_transform(X_train)
            X_test_scaled = self.scalers[group_id].transform(X_test)
            
            # Model eÄŸitimi
            self.models[group_id] = RandomForestRegressor(
                n_estimators=100,
                max_depth=15,
                min_samples_split=5,
                min_samples_leaf=2,
                random_state=42
            )
            
            self.models[group_id].fit(X_train_scaled, y_train)
            
            # Model deÄŸerlendirmesi
            y_pred = self.models[group_id].predict(X_test_scaled)
            rmse = np.sqrt(mean_squared_error(y_test, y_pred))
            r2 = r2_score(y_test, y_pred)
            
            print(f"   âœ… RMSE: {rmse:.3f}, RÂ²: {r2:.3f}")
            print(f"   ğŸ“ˆ Ortalama gÃ¼venli sÃ¼re: {safe_times.mean():.2f} saat")
            print(f"   ğŸ“Š Risk skoru aralÄ±ÄŸÄ±: {risk_scores.min():.3f} - {risk_scores.max():.3f}")
        
        print("\nğŸ¯ TÃ¼m grup modelleri eÄŸitimi tamamlandÄ±!")
    
    def predict_safe_time(self, input_data: Dict[str, Any], group_id: int) -> Dict[str, Any]:
        """
        Belirtilen grup iÃ§in gÃ¼venli vakit tahmin et
        """
        if group_id not in self.models:
            raise ValueError(f"Grup {group_id} iÃ§in model henÃ¼z eÄŸitilmemiÅŸ!")
        
        # Input dataframe oluÅŸtur
        input_df = pd.DataFrame([input_data])
        
        # Ã–zellikleri hazÄ±rla
        feature_df, _ = self.prepare_features(input_df)
        
        # Ã–lÃ§ekle
        feature_scaled = self.scalers[group_id].transform(feature_df)
        
        # Tahmin yap
        predicted_hours = self.models[group_id].predict(feature_scaled)[0]
        
        # Risk skoru hesapla
        risk_score = self.create_composite_risk_score(input_df, group_id)[0]
        
        # Ã–neri oluÅŸtur
        recommendation = self._generate_recommendation(predicted_hours, risk_score, group_id)
        
        return {
            'group_id': group_id,
            'group_name': self.groups[group_id],
            'predicted_safe_hours': round(predicted_hours, 2),
            'risk_score': round(risk_score, 3),
            'recommendation': recommendation,
            'risk_level': self._get_risk_level(risk_score, group_id)
        }
    
    def _generate_recommendation(self, hours: float, risk_score: float, group_id: int) -> str:
        """Tavsiye metni oluÅŸtur"""
        threshold = self.group_weights[group_id]['sensitivity_threshold']
        
        if hours >= 6:
            return f"ğŸŸ¢ Harika! {hours:.1f} saat gÃ¼venle dÄ±ÅŸarÄ±da vakit geÃ§irebilirsiniz."
        elif hours >= 3:
            return f"ğŸŸ¡ {hours:.1f} saat kadar dÄ±ÅŸarÄ±da olabilirsiniz. Dikkatli olun."
        elif hours >= 1:
            return f"ğŸŸ  Sadece {hours:.1f} saat kÄ±sa sÃ¼reli dÄ±ÅŸarÄ± Ã§Ä±kÄ±ÅŸ Ã¶nerilir."
        else:
            return "ğŸ”´ DÄ±ÅŸarÄ± Ã§Ä±kma Ã¶nerilmez. Ä°Ã§ mekanda kalÄ±n."
    
    def _get_risk_level(self, risk_score: float, group_id: int) -> str:
        """Risk seviyesi belirle"""
        threshold = self.group_weights[group_id]['sensitivity_threshold']
        
        if risk_score <= threshold:
            return "DÃ¼ÅŸÃ¼k"
        elif risk_score <= threshold * 1.5:
            return "Orta"
        elif risk_score <= threshold * 2:
            return "YÃ¼ksek"
        else:
            return "Ã‡ok YÃ¼ksek"
    
    def save_models(self, base_path: str):
        """Modelleri kaydet"""
        import os
        os.makedirs(base_path, exist_ok=True)
        
        # Modelleri kaydet
        for group_id in self.models:
            model_path = f"{base_path}/group_{group_id}_model.pkl"
            scaler_path = f"{base_path}/group_{group_id}_scaler.pkl"
            
            with open(model_path, 'wb') as f:
                pickle.dump(self.models[group_id], f)
            with open(scaler_path, 'wb') as f:
                pickle.dump(self.scalers[group_id], f)
        
        # Label encoder'larÄ± kaydet
        encoder_path = f"{base_path}/label_encoders.pkl"
        with open(encoder_path, 'wb') as f:
            pickle.dump(self.label_encoders, f)
        
        # Grup aÄŸÄ±rlÄ±klarÄ±nÄ± kaydet
        weights_path = f"{base_path}/group_weights.json"
        with open(weights_path, 'w') as f:
            json.dump(self.group_weights, f, indent=2)
        
        print(f"ğŸ’¾ Modeller kaydedildi: {base_path}")

if __name__ == "__main__":
    # TemizlenmiÅŸ veriyi yÃ¼kle
    data_path = '/Users/elifdy/Desktop/allermind/aller-mind/DATA/ML/cleaned_combined_data.csv'
    df = pd.read_csv(data_path)
    
    # Predictor oluÅŸtur ve eÄŸit
    predictor = AllergyGroupPredictor()
    predictor.train_group_models(df)
    
    # Modelleri kaydet
    predictor.save_models('/Users/elifdy/Desktop/allermind/aller-mind/DATA/ML/models')
